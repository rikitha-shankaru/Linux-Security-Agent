#!/usr/bin/env python3
"""
Enhanced Linux Security Agent - Research-Based Implementation
Integrates stateful eBPF monitoring, unsupervised anomaly detection, and container security
Based on recent research findings (2023-2025)
"""

import os
import sys
import json
import time
import signal
import argparse
import threading
import random
from collections import defaultdict, deque
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
import traceback

# Add core directory to path for imports
_core_dir = os.path.dirname(os.path.abspath(__file__))
if _core_dir not in sys.path:
    sys.path.insert(0, _core_dir)

try:
    from bcc import BPF
    BCC_AVAILABLE = True
except ImportError:
    BCC_AVAILABLE = False
    print("Warning: BCC not available. Using fallback monitoring.")

import psutil
from rich.console import Console
from rich.table import Table
from rich.live import Live
from rich.panel import Panel
from rich.text import Text
from rich import box
import click

# Import enhanced components
try:
    from enhanced_ebpf_monitor import StatefulEBPFMonitor, ProcessState, SecurityPolicy
    ENHANCED_EBPF_AVAILABLE = True
except ImportError as e:
    ENHANCED_EBPF_AVAILABLE = False
    # Suppress warning - eBPF monitor is critical, but we have fallback

try:
    # First check if dependencies are available
    import numpy
    import pandas
    import sklearn
    # Dependencies exist, try importing the module
    from enhanced_anomaly_detector import EnhancedAnomalyDetector, AnomalyResult, BehavioralBaseline
    ENHANCED_ANOMALY_AVAILABLE = True
except ImportError as e:
    ENHANCED_ANOMALY_AVAILABLE = False
    # Optional component - will work without it

try:
    from container_security_monitor import ContainerSecurityMonitor, ContainerInfo, CrossContainerAttempt
    CONTAINER_SECURITY_AVAILABLE = True
except ImportError as e:
    CONTAINER_SECURITY_AVAILABLE = False
    # Optional component - suppress warning for cleaner output

# Import existing components
try:
    # action_handler is in legacy/, not core/, so it's truly optional
    ACTION_HANDLER_AVAILABLE = False
except ImportError:
    ACTION_HANDLER_AVAILABLE = False
    # Optional component - suppress warning for cleaner output

class EnhancedRiskScorer:
    """
    Enhanced risk scoring system with behavioral baselining and adaptive thresholds
    """
    
    def __init__(self, config: Dict = None):
        self.config = config or {}
        
        # Risk scoring parameters
        self.base_risk_scores = {
            # Low risk - normal operations
            'read': 1, 'write': 1, 'open': 1, 'close': 1, 'lseek': 1,
            'stat': 1, 'fstat': 1, 'lstat': 1, 'access': 1, 'readlink': 1,
            'getcwd': 1, 'chdir': 1, 'fchdir': 1, 'getpid': 1, 'getppid': 1,
            'getuid': 1, 'getgid': 1, 'geteuid': 1, 'getegid': 1,
            'socket': 1, 'bind': 1, 'listen': 1, 'accept': 1, 'connect': 1,
            'send': 1, 'recv': 1, 'sendto': 1, 'recvfrom': 1, 'shutdown': 1,
            
            # Medium risk - potentially suspicious
            'fork': 3, 'vfork': 3, 'clone': 3, 'execve': 5, 'execveat': 5,
            'chmod': 3, 'fchmod': 3, 'chown': 3, 'fchown': 3, 'lchown': 3,
            'rename': 3, 'unlink': 3, 'rmdir': 3, 'mkdir': 3, 'mknod': 3,
            'symlink': 3, 'link': 3, 'mount': 4, 'umount': 4, 'umount2': 4,
            
            # High risk - very suspicious
            'ptrace': 10, 'setuid': 8, 'setgid': 8, 'chroot': 8, 'pivot_root': 8,
            'reboot': 10, 'sethostname': 6, 'setdomainname': 6, 'iopl': 8,
            'ioperm': 8, 'create_module': 10, 'init_module': 10, 'delete_module': 10
        }
        
        # Adaptive risk scoring
        self.process_baselines = {}  # pid -> baseline behavior
        self.risk_history = defaultdict(deque)  # pid -> risk history
        self.adaptive_thresholds = {}  # pid -> adaptive threshold
        
        # Time decay parameters
        self.decay_factor = self.config.get('decay_factor', 0.95)
        self.decay_interval = self.config.get('decay_interval', 60)  # seconds
        
        # Behavioral analysis
        self.behavioral_window = self.config.get('behavioral_window', 100)
        self.anomaly_weight = self.config.get('anomaly_weight', 0.3)
    
    def update_risk_score(self, pid: int, syscalls: List[str], process_info: Dict = None, 
                         anomaly_score: float = 0.0, container_id: str = None) -> float:
        """
        Update risk score with enhanced behavioral analysis
        """
        current_time = time.time()
        
        # Initialize process baseline if needed
        if pid not in self.process_baselines:
            self.process_baselines[pid] = {
                'syscall_frequencies': defaultdict(int),
                'temporal_patterns': deque(maxlen=self.behavioral_window),
                'resource_usage': {},
                'last_updated': current_time,
                'sample_count': 0
            }
        
        baseline = self.process_baselines[pid]
        
        # Calculate base risk score
        base_score = 0.0
        for syscall in syscalls:
            base_score += self.base_risk_scores.get(syscall, 2)
        
        # Normalize by number of syscalls
        if syscalls:
            base_score = base_score / len(syscalls) * 10  # Scale to 0-100
        
        # Apply behavioral analysis
        behavioral_score = self._calculate_behavioral_score(pid, syscalls, process_info)
        
        # Apply container-specific adjustments
        container_score = self._calculate_container_score(pid, syscalls, container_id)
        
        # Combine scores with weights
        final_score = (
            base_score * 0.4 +
            behavioral_score * 0.3 +
            anomaly_score * self.anomaly_weight +
            container_score * 0.1
        )
        
        # Apply time decay
        if pid in self.risk_history and self.risk_history[pid]:
            last_score = self.risk_history[pid][-1]
            time_since_last = current_time - baseline['last_updated']
            
            if time_since_last > self.decay_interval:
                decayed_score = last_score * (self.decay_factor ** (time_since_last / self.decay_interval))
                final_score = max(final_score, decayed_score)
        
        # Update history and baseline
        self.risk_history[pid].append(final_score)
        if len(self.risk_history[pid]) > 50:  # Keep last 50 scores
            self.risk_history[pid].popleft()
        
        self._update_behavioral_baseline(pid, syscalls, process_info)
        
        # Clamp to 0-100 range
        return min(100.0, max(0.0, final_score))
    
    def _calculate_behavioral_score(self, pid: int, syscalls: List[str], process_info: Dict = None) -> float:
        """Calculate behavioral deviation score"""
        if pid not in self.process_baselines:
            return 0.0
        
        baseline = self.process_baselines[pid]
        
        # Calculate syscall frequency deviation
        current_frequencies = defaultdict(int)
        for syscall in syscalls:
            current_frequencies[syscall] += 1
        
        total_syscalls = len(syscalls)
        if total_syscalls == 0:
            return 0.0
        
        # Compare with baseline
        deviation_score = 0.0
        for syscall, count in current_frequencies.items():
            current_freq = count / total_syscalls
            baseline_freq = baseline['syscall_frequencies'].get(syscall, 0) / max(1, baseline['sample_count'])
            
            # Calculate deviation
            deviation = abs(current_freq - baseline_freq)
            deviation_score += deviation * 10  # Scale to 0-100
        
        # Resource usage deviation
        if process_info:
            cpu_deviation = abs(process_info.get('cpu_percent', 0) - baseline['resource_usage'].get('cpu_percent', 0))
            memory_deviation = abs(process_info.get('memory_percent', 0) - baseline['resource_usage'].get('memory_percent', 0))
            
            deviation_score += (cpu_deviation + memory_deviation) * 0.1
        
        return min(100.0, deviation_score)
    
    def _calculate_container_score(self, pid: int, syscalls: List[str], container_id: str = None) -> float:
        """Calculate container-specific risk score"""
        if not container_id:
            return 0.0
        
        # Container-specific risk adjustments
        container_risk = 0.0
        
        # Check for container escape attempts
        escape_syscalls = ['mount', 'umount', 'chroot', 'pivot_root', 'setns']
        for syscall in syscalls:
            if syscall in escape_syscalls:
                container_risk += 5
        
        # Check for privilege escalation
        privilege_syscalls = ['setuid', 'setgid', 'seteuid', 'setegid']
        for syscall in syscalls:
            if syscall in privilege_syscalls:
                container_risk += 3
        
        return min(100.0, container_risk)
    
    def _update_behavioral_baseline(self, pid: int, syscalls: List[str], process_info: Dict = None):
        """Update behavioral baseline for a process"""
        if pid not in self.process_baselines:
            return
        
        baseline = self.process_baselines[pid]
        
        # Update syscall frequencies
        for syscall in syscalls:
            baseline['syscall_frequencies'][syscall] += 1
        
        # Update resource usage
        if process_info:
            baseline['resource_usage'].update({
                'cpu_percent': process_info.get('cpu_percent', 0),
                'memory_percent': process_info.get('memory_percent', 0)
            })
        
        baseline['last_updated'] = time.time()
        baseline['sample_count'] += 1

class EnhancedSecurityAgent:
    """
    Enhanced Linux Security Agent with research-based improvements
    """
    
    def __init__(self, config: Dict = None):
        self.config = config or {}
        self.console = Console()
        self.running = False
        self.debug_mode = config.get('debug', False)
        
        # Enhanced components
        self.enhanced_ebpf_monitor = None
        self.enhanced_anomaly_detector = None
        self.container_security_monitor = None
        self.enhanced_risk_scorer = None
        self.action_handler = None
        
        # Process tracking
        self.processes = {}  # pid -> process info
        self.syscall_counts = defaultdict(int)
        self.security_events = deque(maxlen=10000)
        
        # Statistics
        self.stats = {
            'total_processes': 0,
            'high_risk_processes': 0,
            'anomalies_detected': 0,
            'cross_container_attempts': 0,
            'policy_violations': 0,
            'actions_taken': 0
        }
        
        # Thread lock for process tracking
        self.processes_lock = threading.Lock()
        
        # Rate limiting for debug output (PID -> last print time)
        self._debug_rate_limit = {}  # {pid: last_print_time}
        self._debug_rate_limit_lock = threading.Lock()
        
        # Risk score persistence (optional - load from file if exists)
        self.risk_score_file = self.config.get('risk_score_file', '/tmp/security_agent_risk_scores.json')
        self._saved_risk_scores = {}  # Initialize for deferred restoration
        self._load_risk_scores()
        
        # Initialize components
        self._initialize_components()
    
    def _initialize_components(self):
        """Initialize all enhanced components"""
        # Initialize enhanced risk scorer
        self.enhanced_risk_scorer = EnhancedRiskScorer(self.config)
        
        # Initialize enhanced eBPF monitor
        if ENHANCED_EBPF_AVAILABLE:
            try:
                self.enhanced_ebpf_monitor = StatefulEBPFMonitor(self.config)
                self.console.print("‚úÖ Enhanced eBPF monitor initialized", style="green")
            except Exception as e:
                self.console.print(f"‚ùå Enhanced eBPF monitor failed: {e}", style="red")
        
        # Initialize enhanced anomaly detector
        if ENHANCED_ANOMALY_AVAILABLE:
            try:
                self.enhanced_anomaly_detector = EnhancedAnomalyDetector(self.config)
                self.console.print("‚úÖ Enhanced anomaly detector initialized", style="green")
            except Exception as e:
                self.console.print(f"‚ùå Enhanced anomaly detector failed: {e}", style="red")
        
        # Initialize container security monitor
        if CONTAINER_SECURITY_AVAILABLE:
            try:
                self.container_security_monitor = ContainerSecurityMonitor(self.config)
                # Check if Docker is actually running
                if self.container_security_monitor.docker_available:
                self.console.print("‚úÖ Container security monitor initialized", style="green")
                else:
                    self.console.print("‚ö†Ô∏è Container monitoring disabled (Docker not running)", style="yellow")
            except Exception as e:
                self.console.print(f"‚ö†Ô∏è Container security monitor disabled: {e}", style="yellow")
                self.container_security_monitor = None
        
        # Initialize action handler
        if ACTION_HANDLER_AVAILABLE:
            try:
                self.action_handler = ActionHandler(self.config)
                self.console.print("‚úÖ Action handler initialized", style="green")
            except Exception as e:
                self.console.print(f"‚ùå Action handler failed: {e}", style="red")
    
    def start_monitoring(self):
        """Start enhanced security monitoring"""
        self.console.print("üöÄ Starting Enhanced Linux Security Agent...", style="bold blue")
        
        # Start enhanced eBPF monitoring with callback
        if self.enhanced_ebpf_monitor:
            if self.enhanced_ebpf_monitor.start_monitoring(event_callback=self._handle_syscall_event):
                self.console.print("‚úÖ Enhanced eBPF monitoring started", style="green")
            else:
                self.console.print("‚ùå Failed to start enhanced eBPF monitoring", style="red")
        
        # Start container security monitoring
        if self.container_security_monitor and self.container_security_monitor.docker_available:
            if self.container_security_monitor.start_monitoring():
                self.console.print("‚úÖ Container security monitoring started", style="green")
            else:
                self.console.print("‚ö†Ô∏è Container security monitoring disabled", style="yellow")
        
        # Train anomaly detection models if needed
        if self.enhanced_anomaly_detector and not self.enhanced_anomaly_detector.is_fitted:
            self._train_anomaly_models()
        
        # Start cleanup thread to prevent memory leaks
        self.cleanup_thread = threading.Thread(target=self._cleanup_loop, daemon=True)
        self.cleanup_thread.start()
        self.console.print("‚úÖ Memory cleanup thread started", style="green")
        
        self.running = True
        self.console.print("üéâ Enhanced security monitoring started successfully!", style="bold green")
    
    def _train_anomaly_models(self):
        """Train anomaly detection models with REAL behavior data"""
        self.console.print("üß† Training anomaly detection models with real data...", style="yellow")
        
        # Collect ACTUAL syscall data from running processes
        training_data = []
        collection_time = 60  # Collect for 60 seconds (increased from 30)
        start_time = time.time()
        
        self.console.print(f"üìä Collecting real syscall data for {collection_time} seconds...", style="yellow")
        self.console.print("üí° Tip: Run commands (ls, ps, cat, etc.) in another terminal to generate syscalls!", style="dim")
        
        # Track which processes we've already sampled to avoid duplicates
        sampled_pids = set()
        
        # Collect real data
        iteration = 0
        while (time.time() - start_time) < collection_time:
            iteration += 1
            # Collect from processes we're monitoring
            with self.processes_lock:
                for pid, proc in self.processes.items():
                    # Lower threshold: collect even if process has 5+ syscalls (was 10+)
                    syscalls_list = proc.get('syscalls', [])
                    if len(syscalls_list) >= 5:
                        # Use REAL syscall data - take a snapshot every few seconds per process
                        # This prevents collecting same process data multiple times
                        pid_key = f"{pid}_{iteration // 10}"  # Sample same PID every 10 iterations
                        
                        if pid_key not in sampled_pids:
                            # Deque doesn't support slicing; convert to list first
                            syscalls = list(syscalls_list)[-50:]  # Take last 50 syscalls to get recent behavior
                            
                            # Get REAL process info from psutil
                            try:
                                p = psutil.Process(int(pid))
                process_info = {
                                    'cpu_percent': p.cpu_percent(interval=0.1) or 0,
                                    'memory_percent': p.memory_percent(),
                                    'num_threads': p.num_threads(),
                                    'pid': int(pid)  # Store PID for debugging
                }
                
                training_data.append((syscalls, process_info))
                                sampled_pids.add(pid_key)
                                
                                # Limit to first 500 samples (enough for training)
                                if len(training_data) >= 500:
                                    break
                            except (psutil.NoSuchProcess, psutil.AccessDenied, AttributeError):
                                continue
                
                # Check if we have enough data
                if len(training_data) >= 500:
                    self.console.print(f"‚úÖ Collected enough data ({len(training_data)} samples)!", style="green")
                    break
            
            # Show progress every 10 seconds
            elapsed = time.time() - start_time
            if int(elapsed) % 10 == 0 and elapsed > 0:
                self.console.print(f"üìä Collected {len(training_data)} samples so far... ({int(elapsed)}/{collection_time}s)", style="dim")
            
            time.sleep(0.5)  # Collect every 0.5 seconds
        
        # If still not enough data, supplement with baseline patterns
        if len(training_data) < 50:  # Lower threshold from 100 to 50
            self.console.print("‚ö†Ô∏è Not enough real data, using baseline patterns", style="yellow")
            self.console.print("üí° For better results, generate system activity during training!", style="dim")
            if self.config.get('debug', False):
                self.console.print(f"üêõ DEBUG: Only collected {len(training_data)} samples, need 50+", style="dim")
            baseline_data = self._get_baseline_patterns()
            training_data.extend(baseline_data)
            if self.config.get('debug', False):
                self.console.print(f"üêõ DEBUG: Added {len(baseline_data)} baseline samples", style="dim")
        elif len(training_data) < 100:
            self.console.print(f"‚úÖ Collected {len(training_data)} real training samples (supplemented with baseline)", style="green")
            # Add some baseline data but keep real data primary
            baseline_data = self._get_baseline_patterns()[:100]  # Add 100 baseline samples
            training_data.extend(baseline_data)
        else:
            self.console.print(f"‚úÖ Collected {len(training_data)} real training samples", style="green")
        
        # Train models on REAL data
        if self.enhanced_anomaly_detector and training_data:
            if self.config.get('debug', False):
                # Count unique processes in training data
                unique_pids = set()
                total_syscalls = 0
                for seq, info in training_data:
                    if seq:
                        total_syscalls += len(seq)
                    if isinstance(info, dict) and 'pid' in info:
                        unique_pids.add(info['pid'])
                
                self.console.print(f"üêõ DEBUG: Training on {len(training_data)} samples from {len(unique_pids)} processes", style="dim")
                if total_syscalls > 0:
                    avg_syscalls = total_syscalls / len(training_data)
                    self.console.print(f"üêõ DEBUG: Total syscalls: {total_syscalls}, Avg per sample: {avg_syscalls:.1f}", style="dim")
            
        self.enhanced_anomaly_detector.train_models(training_data)
            self.console.print("‚úÖ Anomaly detection models trained on REAL data", style="green")
        else:
            self.console.print("‚ö†Ô∏è No data to train on", style="yellow")
    
    def _get_baseline_patterns(self):
        """Get baseline syscall patterns for common processes"""
        patterns = {
            'text_editor': ['open', 'read', 'write', 'close', 'select', 'mmap', 'munmap'],
            'web_browser': ['socket', 'connect', 'send', 'recv', 'poll', 'read', 'write', 'mmap'],
            'shell': ['fork', 'execve', 'wait', 'read', 'write', 'chdir', 'getcwd', 'close'],
            'file_manager': ['open', 'stat', 'getdents', 'readlink', 'close', 'access', 'fstat'],
        }
        
        training_data = []
        for pattern_type, syscalls in patterns.items():
            for _ in range(50):  # 50 samples per pattern
                # Create realistic sequences with repetition
                sequence = []
                for syscall in syscalls:
                    # Add realistic repetition
                    for _ in range(random.randint(1, 3)):
                        sequence.append(syscall)
                
                process_info = {
                    'cpu_percent': random.uniform(1, 20),
                    'memory_percent': random.uniform(1, 10),
                    'num_threads': random.randint(1, 5)
                }
                
                training_data.append((sequence, process_info))
        
        return training_data
    
    def _cleanup_old_processes(self):
        """Remove stale processes to prevent memory leaks - also clean CPU cache"""
        current_time = time.time()
        stale_pids = []
        
        with self.processes_lock:
            for pid, proc in list(self.processes.items()):
                # Remove if not updated in 5 minutes
                last_update = proc.get('last_update', 0)
                if current_time - last_update > 300:  # 5 minutes
                    stale_pids.append(pid)
            
            # Remove stale processes
            for pid in stale_pids:
                if pid in self.processes:
                    del self.processes[pid]
        
        # Clean up CPU cache for stale processes
        if stale_pids and hasattr(self, '_cpu_cache'):
            with getattr(self, '_cpu_cache_lock', threading.Lock()):
                for pid in stale_pids:
                    cache_key = f"cpu_cache_{pid}"
                    cache_time_key = f"cpu_time_{pid}"
                    self._cpu_cache.pop(cache_key, None)
                    self._cpu_cache_time.pop(cache_time_key, None)
        
        if stale_pids:
            self.console.print(f"üßπ Cleaned up {len(stale_pids)} stale processes", style="dim")
    
    def _cleanup_loop(self):
        """Periodic cleanup loop to prevent memory leaks"""
        while self.running:
            try:
                self._cleanup_old_processes()
                # Check running flag VERY frequently (every 0.1s for fast exit)
                for _ in range(600):  # 600 x 0.1 = 60 seconds total
                    if not self.running:
                        return
                    time.sleep(0.1)  # Check every 100ms instead of 1s
            except Exception:
                # Exit on any exception if we're shutting down
                if not self.running:
                    return
                # Check again before sleeping
                if not self.running:
                    return
                time.sleep(0.1)  # Check more frequently
    
    def stop_monitoring(self):
        """Stop enhanced security monitoring - NON-BLOCKING"""
        if not self.running:
            return  # Already stopped
        
        print("\nüõë Stopping Enhanced Linux Security Agent...", flush=True)
        
        # Set running=False FIRST before any other operations
        self.running = False
        
        # Stop enhanced eBPF monitoring immediately (non-blocking)
        if self.enhanced_ebpf_monitor:
            try:
                self.enhanced_ebpf_monitor.running = False  # Force stop first
            self.enhanced_ebpf_monitor.stop_monitoring()
            except:
                pass
        
        # Stop container security monitoring (non-blocking - threads are daemon or have timeout)
        if self.container_security_monitor:
            try:
                self.container_security_monitor.running = False
                # Don't wait for threads - they're daemon or have timeout
            except:
                pass
        
        # Save risk scores before shutdown (fast, non-blocking)
        try:
            self._save_risk_scores()
        except:
            pass
        
        print("‚úÖ Enhanced security monitoring stopped", flush=True)
    
    def _load_risk_scores(self):
        """Load risk scores from previous run if available - with validation"""
        try:
            if os.path.exists(self.risk_score_file):
                # Check file size to avoid loading corrupted huge files
                if os.path.getsize(self.risk_score_file) > 10 * 1024 * 1024:  # 10MB limit
                    return  # File too large, likely corrupted
                
                with open(self.risk_score_file, 'r') as f:
                    saved_data = json.load(f)
                    
                # Validate JSON structure
                if not isinstance(saved_data, dict):
                    return  # Invalid structure
                
                # Store for later restoration (processes dict may be empty at init)
                # We'll restore after processes are populated during monitoring
                self._saved_risk_scores = saved_data
        except (json.JSONDecodeError, OSError, ValueError):
            # File corrupted or invalid - will start fresh
            self._saved_risk_scores = {}
        except Exception:
            pass  # Ignore other errors - start fresh if file doesn't exist
    
    def _save_risk_scores(self):
        """Save current risk scores to file for next run - ATOMIC WRITE"""
        try:
            saved_data = {}
            with self.processes_lock:
                for pid, proc in self.processes.items():
                    if proc.get('risk_score', 0) > 0:
                        saved_data[str(pid)] = {
                            'risk_score': proc.get('risk_score', 0),
                            'name': proc.get('name', 'unknown'),
                            'last_seen': time.time()
                        }
            if saved_data:
                # Atomic write: write to temp file first, then rename
                temp_file = self.risk_score_file + '.tmp'
                try:
                    with open(temp_file, 'w') as f:
                        json.dump(saved_data, f, indent=2)
                        f.flush()
                        os.fsync(f.fileno())  # Force write to disk
                    # Atomic rename (rename is atomic on POSIX systems)
                    os.rename(temp_file, self.risk_score_file)
                except Exception:
                    # Clean up temp file if rename fails
                    try:
                        if os.path.exists(temp_file):
                            os.remove(temp_file)
                    except:
                        pass
        except Exception:
            pass  # Ignore errors - not critical
    
    def _handle_syscall_event(self, pid: int, syscall: str, event_info: Dict = None):
        """Handle syscall event from eBPF monitor"""
        # Get process info from psutil (non-blocking)
        process_info = None
        try:
            proc = psutil.Process(pid)
            # Cache CPU calculation - call it once per second per process
            cache_key = f"cpu_cache_{pid}"
            cache_time_key = f"cpu_time_{pid}"
            
            if not hasattr(self, '_cpu_cache'):
                self._cpu_cache = {}
                self._cpu_cache_time = {}
                self._cpu_cache_lock = threading.Lock()  # Lock for cache access
            
            current_time = time.time()
            
            # Thread-safe cache access
            with getattr(self, '_cpu_cache_lock', threading.Lock()):
                last_cache_time = self._cpu_cache_time.get(cache_time_key, 0)
                
                # Update CPU every 1 second per process (to avoid overhead)
                # cpu_percent(interval=None) is non-blocking but requires previous call
                # We use cached value and only update occasionally
                if current_time - last_cache_time >= 1.0:
                    try:
                        # Non-blocking call - returns 0.0 if not previously initialized
                        # Actual value accumulates over time, so we use cached value
                        cpu_val = proc.cpu_percent(interval=None)
                        if cpu_val == 0.0:
                            # First call or no CPU usage - use cached if available
                            cpu_val = self._cpu_cache.get(cache_key, 0.0)
                        else:
                            # Store for next time
                            self._cpu_cache[cache_key] = cpu_val
                            self._cpu_cache_time[cache_time_key] = current_time
                    except:
                        # Use cached value if process check fails
                        cpu_val = self._cpu_cache.get(cache_key, 0.0)
                else:
                    # Use cached value (updated within last second)
                    cpu_val = self._cpu_cache.get(cache_key, 0.0)
            
            process_info = {
                'cpu_percent': cpu_val,
                'memory_percent': proc.memory_percent(),
                'num_threads': proc.num_threads()
            }
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            process_info = None
        except Exception:
            # Ignore errors - not critical
            process_info = None
        
        self.process_syscall_event(pid, syscall, process_info)
    
    def process_syscall_event(self, pid: int, syscall: str, process_info: Dict = None):
        """Process a system call event with enhanced analysis"""
        try:
            # Get container information - THREAD SAFE
            container_id = None
            if self.container_security_monitor:
                try:
                    # Use thread-safe method if available, otherwise access with lock
                    if hasattr(self.container_security_monitor, 'containers_lock'):
                        with self.container_security_monitor.containers_lock:
                container_id = self.container_security_monitor.process_containers.get(pid)
                    elif hasattr(self.container_security_monitor, 'process_containers'):
                        container_id = self.container_security_monitor.process_containers.get(pid)
                except (AttributeError, RuntimeError):
                    # Container monitor not fully initialized or lock unavailable
                    pass
            
            # Validate syscall against container policy
            if self.container_security_monitor:
                try:
                if not self.container_security_monitor.validate_syscall(pid, syscall):
                    self.stats['policy_violations'] += 1
                    return
                except (AttributeError, Exception) as e:
                    # Graceful degradation if container check fails
                    pass
            
            # Get process state from enhanced eBPF monitor
            process_state = None
            if self.enhanced_ebpf_monitor:
                try:
                process_state = self.enhanced_ebpf_monitor.get_process_state(pid)
                except (AttributeError, Exception) as e:
                    # eBPF monitor not available or failed
                    pass
            
            # Update process information with thread safety (ONE lock for all updates)
            current_time = time.time()
            process_snapshot = None
            risk_score = 0.0
            should_log_high_risk = False
            
            with self.processes_lock:
            if pid not in self.processes:
                    try:
                        # Restore saved risk score if available
                        saved_score = 0.0
                        if hasattr(self, '_saved_risk_scores') and self._saved_risk_scores:
                            saved_data = self._saved_risk_scores.get(str(pid))
                            if saved_data and isinstance(saved_data, dict):
                                saved_score = saved_data.get('risk_score', 0.0)
                        
                self.processes[pid] = {
                    'name': self._get_process_name(pid),
                            'risk_score': saved_score,  # Restore from previous run
                    'anomaly_score': 0.0,
                    'syscall_count': 0,
                            'last_update': current_time,
                            'last_risk_update': current_time,
                            'syscalls': deque(maxlen=1000),  # Bounded deque
                    'container_id': container_id,
                    'process_state': process_state
                }
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        # Process already gone, skip
                        return
            
            process = self.processes[pid]
                process['syscalls'].append(syscall)  # Deque auto-bounds
            process['syscall_count'] += 1
                process['last_update'] = current_time
                
                # Update CPU usage periodically (every 10 syscalls to avoid overhead)
                if process['syscall_count'] % 10 == 0 and process_info:
                    cpu_val = process_info.get('cpu_percent', 0.0)
                    process['cpu_percent'] = cpu_val if cpu_val is not None else 0.0
                
                # Create snapshot while still in lock
                process_snapshot = dict(process)
                process_snapshot['syscalls'] = list(process['syscalls'])
                
                # Calculate risk score while in lock
                if self.enhanced_risk_scorer:
                    # Apply time decay first
                    if 'last_risk_update' in process:
                        time_since_last = current_time - process['last_risk_update']
                        # Decay: lose 1% per second
                        decay_factor = 0.99 ** time_since_last
                        process['risk_score'] = process['risk_score'] * decay_factor
                    
                    # Calculate new risk score
                    risk_score = self.enhanced_risk_scorer.update_risk_score(
                        pid, list(process['syscalls']), process_info, 
                        process.get('anomaly_score', 0.0), container_id
                    )
                    
                    # Smooth with previous score (exponential moving average)
                    old_risk_score = process.get('risk_score', 0.0)
                    if old_risk_score > 0:
                        new_risk_score = 0.7 * risk_score + 0.3 * old_risk_score
                    else:
                        new_risk_score = risk_score
                    
                    process['risk_score'] = new_risk_score
                    process['last_risk_update'] = current_time
                    
                    # Check for high-risk processes - only increment when CROSSING threshold
                    risk_threshold = self.config.get('risk_threshold', 50.0)
                    if new_risk_score >= risk_threshold and old_risk_score < risk_threshold:
                        # Process just crossed the high-risk threshold
                        self.stats['high_risk_processes'] += 1
                        should_log_high_risk = True
                    elif new_risk_score >= risk_threshold:
                        # Process is already high-risk, but log if needed
                        should_log_high_risk = False  # Don't spam logs
            
            # Now do heavy work OUTSIDE the lock (anomaly detection is expensive)
            if not process_snapshot:
                return
            
            # Enhanced anomaly detection (OUTSIDE lock - this is expensive)
            anomaly_result = None
            if self.enhanced_anomaly_detector:
                try:
                anomaly_result = self.enhanced_anomaly_detector.detect_anomaly_ensemble(
                        process_snapshot['syscalls'], process_info, pid
                )
                    
                    # Update anomaly score back in process (with lock)
                    with self.processes_lock:
                        if pid in self.processes:
                            old_score = self.processes[pid].get('anomaly_score', 0.0)
                            self.processes[pid]['anomaly_score'] = anomaly_result.anomaly_score
                
                            # Count anomalies (only increment when crossing threshold to avoid double-counting)
                            if anomaly_result.is_anomaly and old_score < 0.5:
                    self.stats['anomalies_detected'] += 1
                                
                                # Debug mode: only show when anomaly is FIRST detected (threshold crossing)
                                if self.config.get('debug', False):
                                    try:
                                        with self._debug_rate_limit_lock:
                                            current_time = time.time()
                                            last_print = self._debug_rate_limit.get(pid, 0)
                                            # Only print once per PID every 10 seconds
                                            if current_time - last_print >= 10.0:
                                                print(f"üêõ DEBUG Anomaly DETECTED: PID={pid} ({process_snapshot.get('name', 'unknown')}) "
                                                      f"score={anomaly_result.anomaly_score:.2f}, "
                                                      f"confidence={anomaly_result.confidence:.2f}, "
                                                      f"explanation={anomaly_result.explanation[:80] if anomaly_result.explanation else 'N/A'}")
                                                self._debug_rate_limit[pid] = current_time
                                    except AttributeError:
                                        # Fallback if lock doesn't exist (shouldn't happen, but handle gracefully)
                                        pass
                            elif self.config.get('debug', False) and anomaly_result.is_anomaly:
                                # Rate limit: only log significant changes once per 10 seconds
                                try:
                                    with self._debug_rate_limit_lock:
                                        current_time = time.time()
                                        last_print = self._debug_rate_limit.get(pid, 0)
                                        # Only log if score changed by 10+ points AND 10 seconds have passed
                                        if abs(old_score - anomaly_result.anomaly_score) >= 10.0 and (current_time - last_print) >= 10.0:
                                            print(f"üêõ DEBUG Anomaly UPDATE: PID={pid} score={anomaly_result.anomaly_score:.2f} (was {old_score:.2f})")
                                            self._debug_rate_limit[pid] = current_time
                                except AttributeError:
                                    # Fallback if lock doesn't exist (shouldn't happen, but handle gracefully)
                                    pass
                    
                    if anomaly_result.is_anomaly:
                    self._log_security_event('anomaly_detected', {
                        'pid': pid,
                            'process_name': process_snapshot['name'],
                        'anomaly_score': anomaly_result.anomaly_score,
                        'explanation': anomaly_result.explanation
                    })
                except Exception as e:
                    print(f"Anomaly detection error: {e}")
            
            # Log high-risk event (use snapshot data)
            if should_log_high_risk:
                self._log_security_event('high_risk_process', {
                    'pid': pid,
                    'process_name': process_snapshot['name'],
                    'risk_score': risk_score,
                    'anomaly_score': process_snapshot.get('anomaly_score', 0.0)
                })
            
            # Take action if needed (with lock)
            if self.action_handler:
                try:
                    with self.processes_lock:
                        if pid in self.processes:
                            process = self.processes[pid]
                self.action_handler.take_action(
                                pid, process['name'], process['risk_score'], 
                                process.get('anomaly_score', 0.0)
                )
                self.stats['actions_taken'] += 1
                except Exception as e:
                    print(f"Action handler error: {e}")
            
            # Update statistics (no lock needed for syscall_counts, it's thread-safe defaultdict)
            self.syscall_counts[syscall] += 1
            
            # Update total processes count (every syscall to keep it accurate)
            with self.processes_lock:
            self.stats['total_processes'] = len(self.processes)
            
        except Exception as e:
            self.console.print(f"‚ùå Error processing syscall event: {e}", style="red")
            self.console.print(f"Traceback: {traceback.format_exc()}", style="red")
    
    def _get_process_name(self, pid: int) -> str:
        """Get process name by PID"""
        try:
            process = psutil.Process(pid)
            return process.name()
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            return f"<unknown:{pid}>"
    
    def _log_security_event(self, event_type: str, details: Dict):
        """Log security event"""
        event = {
            'timestamp': time.time(),
            'event_type': event_type,
            'details': details
        }
        self.security_events.append(event)
    
    def get_high_risk_processes(self, threshold: float = 50.0) -> List[Tuple[int, str, float, float]]:
        """Get processes with risk scores above threshold"""
        high_risk = []
        # Thread-safe access to processes
        with self.processes_lock:
            processes_snapshot = dict(self.processes)
        
        for pid, process in processes_snapshot.items():
            risk_score = process.get('risk_score', 0) or 0
            if risk_score >= threshold:
                anomaly_score = process.get('anomaly_score', 0.0)
                high_risk.append((pid, process['name'], risk_score, anomaly_score))
        return sorted(high_risk, key=lambda x: x[2], reverse=True)
    
    def get_monitoring_stats(self) -> Dict[str, Any]:
        """Get comprehensive monitoring statistics"""
        stats = {
            **self.stats,
            'enhanced_ebpf_stats': self.enhanced_ebpf_monitor.get_monitoring_stats() if self.enhanced_ebpf_monitor else {},
            'anomaly_detection_stats': self.enhanced_anomaly_detector.get_detection_stats() if self.enhanced_anomaly_detector else {},
            'container_security_stats': self.container_security_monitor.get_security_stats() if self.container_security_monitor else {},
            'total_syscalls': sum(self.syscall_counts.values()),
            'unique_syscalls': len(self.syscall_counts),
            'security_events': len(self.security_events)
        }
        return stats
    
    def export_monitoring_data(self) -> Dict[str, Any]:
        """Export comprehensive monitoring data"""
        data = {
            'processes': self.processes,
            'syscall_counts': dict(self.syscall_counts),
            'security_events': list(self.security_events),
            'stats': self.get_monitoring_stats(),
            'export_timestamp': time.time()
        }
        
        # Add enhanced component data
        if self.enhanced_ebpf_monitor:
            data['enhanced_ebpf_data'] = self.enhanced_ebpf_monitor.export_state_data()
        
        if self.enhanced_anomaly_detector:
            data['anomaly_detection_data'] = self.enhanced_anomaly_detector.export_anomaly_data()
        
        if self.container_security_monitor:
            data['container_security_data'] = self.container_security_monitor.export_security_data()
        
        return data
    
    def _create_dashboard(self):
        """Create detailed real-time monitoring dashboard"""
        
        # Main processes table - fixed widths to prevent wrapping
        table = Table(
            title="üñ•Ô∏è Live Process Monitoring", 
            box=box.ROUNDED, 
            show_header=True, 
            header_style="bold",
            padding=(0, 1)
        )
        # Column widths: 8+18+10+8+10+8 = 62 chars + 7 borders = ~69 total width needed
        table.add_column("PID", style="cyan", no_wrap=True, width=7, justify="right", overflow="ignore")
        table.add_column("Process Name", style="magenta", width=16, no_wrap=True, overflow="ellipsis")
        table.add_column("Risk", justify="right", style="yellow", width=9, no_wrap=True, overflow="ignore")
        table.add_column("Anomaly", justify="center", style="yellow", width=7, no_wrap=True, overflow="ignore")
        table.add_column("Syscalls", justify="right", style="green", width=9, no_wrap=True, overflow="ignore")
        table.add_column("CPU%", justify="right", style="cyan", width=7, no_wrap=True, overflow="ignore")
        
        # Add processes sorted by risk score - THREAD SAFE: create snapshot under lock
        with self.processes_lock:
            # Create snapshot to avoid holding lock during expensive operations
            processes_snapshot = {
                pid: dict(proc) for pid, proc in self.processes.items()
            }
        
        # Sort outside the lock (safe because we have a snapshot)
        sorted_processes = sorted(
            processes_snapshot.items(),
            key=lambda x: x[1].get('risk_score', 0) or 0,
            reverse=True
        )[:10]  # Show top 10
        
        if sorted_processes:
        for pid, proc in sorted_processes:
            risk_score = proc.get('risk_score', 0) or 0
            anomaly_score = proc.get('anomaly_score', 0.0)
                syscall_count = proc.get('syscall_count', 0)
                
                # Risk indicator
                if risk_score >= 50:
                    risk_display = f"üî¥ {risk_score:.0f}"
                elif risk_score >= 30:
                    risk_display = f"üü° {risk_score:.0f}"
                else:
                    risk_display = f"üü¢ {risk_score:.0f}"
                
                # Anomaly indicator (simplified)
                if anomaly_score >= 0.5:
                    anomaly_display = "‚ö†Ô∏è"
                else:
                    anomaly_display = "‚úì"
                
                # Get CPU usage - check if we've stored it in process dict
                # (we update it during syscall processing)
                cpu_percent = proc.get('cpu_percent', None)
                if cpu_percent is not None:
                    # Cap CPU at 100% (psutil can show >100% on multi-core, normalize)
                    cpu_percent = min(100.0, max(0.0, cpu_percent))
                    cpu_display = f"{cpu_percent:.1f}%"
                else:
                    # Try to get it from psutil (may be 0.0 if just started)
                    try:
                        p = psutil.Process(int(pid))
                        # Get CPU - may be 0.0% if process is idle or just started
                        cpu = p.cpu_percent(interval=None) or 0.0
                        cpu = min(100.0, max(0.0, cpu))  # Cap at 100%
                        cpu_display = f"{cpu:.1f}%"
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        cpu_display = "N/A"
                    except:
                        cpu_display = "0.0%"
                
                # Format syscall count properly
                syscall_display = f"{syscall_count:,}" if syscall_count > 0 else "0"
                
                # Truncate process name if too long
                proc_name = proc.get('name', '<unknown>')
                if len(proc_name) > 17:
                    proc_name = proc_name[:14] + "..."
            
            table.add_row(
                str(pid),
                    proc_name,
                    risk_display,
                    anomaly_display,
                    syscall_display,
                    cpu_display
                )
        else:
            table.add_row("Waiting for syscall events...", "", "", "", "", "", style="dim")
        
        # Stats panel with explanations
        stats_panel_content = f"""
üìä **Statistics**
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üîç Processes Monitored: {self.stats['total_processes']}
   ‚Üí Total unique processes captured by eBPF

‚ö†Ô∏è  High Risk Processes: {self.stats['high_risk_processes']}  
   ‚Üí Processes that crossed risk threshold (score ‚â• 50)
   ‚Üí Count shows how many processes became high-risk, not current count
   ‚Üí Current high-risk processes shown in table above (üî¥ indicator)

üö® Anomalies Detected: {self.stats['anomalies_detected']}
   ‚Üí Processes that crossed anomaly threshold (score ‚â• 0.5)
   ‚Üí Current anomaly scores stored per-process in table above
   ‚Üí ML ensemble (Isolation Forest + One-Class SVM + DBSCAN) analyzes patterns
   ‚Üí Note: Same process can trigger multiple times if behavior changes

üîí Policy Violations: {self.stats['policy_violations']}
   ‚Üí Container security policy violations (currently 0)

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üéØ **What's Happening:**
‚Ä¢ eBPF is capturing system calls from running processes
‚Ä¢ ML models are analyzing behavior patterns in real-time
‚Ä¢ Risk scores combine syscall analysis + behavioral baselining
‚Ä¢ Anomaly detection uses ensemble of 3 ML algorithms
‚Ä¢ Dashboard updates every second

üí° **Risk Score Meaning:**
   üü¢ 0-30:  Normal system activity
   üü° 30-50: Potentially suspicious
   üî¥ 50+:   High risk - investigate immediately
        """
        
        # Combine everything - Rich will handle table rendering
        from rich.console import Console
        from io import StringIO
        
        # Increase console width to prevent table wrapping (~70 chars for table + borders)
        string_console = Console(file=StringIO(), force_terminal=True, width=150, legacy_windows=False)
        string_console.print(table, overflow="ignore")
        table_str = string_console.file.getvalue()
        
        content = f"\n{table_str}\n\n{stats_panel_content}"
        
        return Panel(content, title="üõ°Ô∏è Enhanced Linux Security Agent - Real-time Monitoring", 
                    border_style="green", padding=(0, 1))
    
    def _list_processes(self):
        """List all monitored processes"""
        print("\n" + "="*80)
        print("üìã MONITORED PROCESSES")
        print("="*80)
        
        with self.processes_lock:
            if not self.processes:
                print("No processes monitored yet.")
                return
            
            # Sort by risk score - THREAD SAFE: create snapshot
            processes_snapshot = dict(self.processes)
        
        # Sort outside the lock
        sorted_procs = sorted(
            processes_snapshot.items(),
            key=lambda x: x[1].get('risk_score', 0) or 0,
            reverse=True
        )
        
        print(f"\nTotal Processes: {len(sorted_procs)}\n")
        print(f"{'PID':<8} {'Process Name':<20} {'Risk':<8} {'Syscalls':<12} {'Anomaly':<10}")
        print("-" * 80)
        
        for pid, proc in sorted_procs:
            risk = proc.get('risk_score', 0) or 0
            name = proc.get('name', '<unknown>')[:19]
            syscalls = proc.get('syscall_count', 0)
            anomaly = proc.get('anomaly_score', 0.0)
            anomaly_str = f"‚ö†Ô∏è {anomaly:.2f}" if anomaly >= 0.5 else f"‚úì {anomaly:.2f}"
            
            print(f"{pid:<8} {name:<20} {risk:<8.0f} {syscalls:<12} {anomaly_str:<10}")
        
        print("\n" + "="*80 + "\n")
    
    def _list_anomalies(self):
        """List all detected anomalies"""
        print("\n" + "="*80)
        print("üö® DETECTED ANOMALIES")
        print("="*80)
        
        with self.processes_lock:
            # Create snapshot under lock
            processes_snapshot = {pid: dict(proc) for pid, proc in self.processes.items()}
        
        # Process outside lock
        anomalies = []
        for pid, proc in processes_snapshot.items():
            anomaly_score = proc.get('anomaly_score', 0.0)
            if anomaly_score >= 0.5:
                anomalies.append({
                    'pid': pid,
                    'name': proc.get('name', '<unknown>'),
                    'anomaly_score': anomaly_score,
                    'risk_score': proc.get('risk_score', 0) or 0,
                    'syscall_count': proc.get('syscall_count', 0)
                })
        
        if not anomalies:
            print("\n‚úÖ No anomalies detected.\n")
            return
        
        # Sort by anomaly score
        anomalies.sort(key=lambda x: x['anomaly_score'], reverse=True)
        
        print(f"\nTotal Anomalies: {len(anomalies)}\n")
        print(f"{'PID':<8} {'Process Name':<20} {'Anomaly Score':<15} {'Risk':<8} {'Syscalls':<10}")
        print("-" * 80)
        
        for anom in anomalies:
            print(f"{anom['pid']:<8} {anom['name'][:19]:<20} {anom['anomaly_score']:<15.2f} "
                  f"{anom['risk_score']:<8.0f} {anom['syscall_count']:<10}")
        
        print("\n" + "="*80 + "\n")
    
    def _show_stats(self):
        """Show comprehensive statistics"""
        print("\n" + "="*80)
        print("üìä MONITORING STATISTICS")
        print("="*80)
        
        stats = self.get_monitoring_stats()
        
        print(f"\nüîç Processes Monitored: {stats.get('total_processes', 0)}")
        print(f"‚ö†Ô∏è  High Risk Processes: {stats.get('high_risk_processes', 0)}")
        print(f"üö® Anomalies Detected: {stats.get('anomalies_detected', 0)}")
        print(f"üîí Policy Violations: {stats.get('policy_violations', 0)}")
        print(f"üì° Total Syscalls Captured: {stats.get('total_syscalls', 0)}")
        print(f"üî¢ Unique Syscall Types: {stats.get('unique_syscalls', 0)}")
        
        if self.enhanced_ebpf_monitor:
            ebpf_stats = stats.get('enhanced_ebpf_stats', {})
            if 'events_captured' in ebpf_stats:
                print(f"üì• eBPF Events Captured: {ebpf_stats['events_captured']}")
        
        if self.enhanced_anomaly_detector:
            anom_stats = stats.get('anomaly_detection_stats', {})
            print(f"\nüß† ML Model Statistics:")
            print(f"   Total Detections: {anom_stats.get('total_detections', 0)}")
            print(f"   True Positives: {anom_stats.get('true_positives', 0)}")
        
        print("\n" + "="*80 + "\n")

def main():
    """Main function for enhanced security agent"""
    parser = argparse.ArgumentParser(description='Enhanced Linux Security Agent')
    parser.add_argument('--dashboard', action='store_true', help='Show real-time dashboard')
    parser.add_argument('--threshold', type=float, default=50.0, help='Risk threshold for alerts')
    parser.add_argument('--timeout', type=int, default=0, help='Run for specified seconds (0 = indefinitely)')
    parser.add_argument('--output', choices=['console', 'json'], default='console', help='Output format')
    parser.add_argument('--config', type=str, help='Configuration file path')
    parser.add_argument('--train-models', action='store_true', help='Train anomaly detection models')
    parser.add_argument('--list-processes', action='store_true', help='List all monitored processes and exit')
    parser.add_argument('--list-anomalies', action='store_true', help='List all detected anomalies and exit')
    parser.add_argument('--stats', action='store_true', help='Show statistics and exit')
    parser.add_argument('--debug', action='store_true', help='Enable debug mode with detailed logging')
    parser.add_argument('--daemon', action='store_true', help='Run as background daemon (logs to file)')
    parser.add_argument('--log-file', type=str, default='/tmp/security_agent.log', help='Log file for daemon mode')
    
    args = parser.parse_args()
    
    # Load configuration
    config = {}
    if args.config and os.path.exists(args.config):
        with open(args.config, 'r') as f:
            config = json.load(f)
    
    config.update({
        'risk_threshold': args.threshold,
        'output_format': args.output,
        'debug': args.debug or config.get('debug', False)
    })
    
    # Handle daemon mode (background operation) - FUTURE IMPLEMENTATION
    if args.daemon:
        print("‚ö†Ô∏è  Daemon mode coming soon!")
        print("For now, use: nohup sudo python3 core/enhanced_security_agent.py --dashboard --timeout 3600 > /tmp/agent.log 2>&1 &")
        print("Then check logs: tail -f /tmp/agent.log")
        sys.exit(0)
    
    # Create enhanced security agent
    agent = EnhancedSecurityAgent(config)
    
    # Train models if requested
    if args.train_models and agent.enhanced_anomaly_detector:
        agent._train_anomaly_models()
        return
    
    # Handle query commands (list processes, anomalies, stats)
    if args.list_processes or args.list_anomalies or args.stats:
        # Need to start monitoring briefly to collect data
        agent.start_monitoring()
        time.sleep(5)  # Collect data for 5 seconds
        
        if args.list_processes:
            agent._list_processes()
        elif args.list_anomalies:
            agent._list_anomalies()
        elif args.stats:
            agent._show_stats()
        
        agent.stop_monitoring()
        return
    
    # Set up signal handlers for clean exit - MUST be before start_monitoring
    exit_requested = threading.Event()
    shutdown_initiated = False
    
    def signal_handler(signum, frame):
        nonlocal shutdown_initiated
        # Write directly to stderr for immediate visibility (stdout might be buffered)
        import sys
        sys.stderr.write("\nüõë Ctrl+C detected! Stopping agent...\n")
        sys.stderr.flush()
        
        # Set exit flags IMMEDIATELY
        exit_requested.set()
        agent.running = False
        
        # Force immediate stop of all threads
        if agent.enhanced_ebpf_monitor:
            agent.enhanced_ebpf_monitor.running = False
        
        if shutdown_initiated:
            # Force immediate exit on second Ctrl+C (within 2 seconds)
            sys.stderr.write("üõë Force exit!\n")
            sys.stderr.flush()
            os._exit(1)
        
        shutdown_initiated = True
    
    # Install signal handlers
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # Start monitoring
    agent.start_monitoring()
    
    try:
        start_time = time.time()
        
        if args.dashboard:
            # Show real-time dashboard - use Live with screen=False for better signal handling
            from rich.live import Live
            live = None
            try:
                live = Live(agent._create_dashboard(), refresh_per_second=2, screen=False)
                live.start()
                
                while agent.running and not exit_requested.is_set():
                    elapsed = time.time() - start_time
                    if args.timeout > 0 and elapsed >= args.timeout:
                        print(f"\n‚è∞ Timeout reached ({args.timeout}s) - stopping agent...", flush=True)
                        agent.running = False
                        exit_requested.set()
                        break
                    
                    if exit_requested.is_set() or not agent.running:
                        break
                    
                    # Check exit BEFORE expensive dashboard creation
                    if exit_requested.is_set() or not agent.running:
                        break
                    
                    try:
                        dashboard = agent._create_dashboard()
                        # Check exit AGAIN before updating
                        if exit_requested.is_set() or not agent.running:
                            break
                        live.update(dashboard)
                    except (KeyboardInterrupt, SystemExit):
                        exit_requested.set()
                        agent.running = False
                        break
                    except Exception:
                        # Suppress dashboard errors during shutdown
                        if exit_requested.is_set() or not agent.running:
                            break
                        pass
                    
                    # Very short sleep - check exit VERY frequently
                    if exit_requested.is_set() or not agent.running:
                        break
                    time.sleep(0.05)  # 50ms - allows signal handler to work
            except (KeyboardInterrupt, SystemExit):
                agent.running = False
            finally:
                if live:
                    try:
                        # Stop Live immediately, don't wait
                        live.stop()
                        live.refresh()
                    except:
                        pass
                # Force exit flag
                exit_requested.set()
        else:
            # Run without dashboard
            while agent.running and not exit_requested.is_set():
                # Check exit BEFORE expensive operations
                if exit_requested.is_set() or not agent.running:
                    break
                
                elapsed = time.time() - start_time
                if args.timeout > 0 and elapsed >= args.timeout:
                    print(f"\n‚è∞ Timeout reached ({args.timeout}s) - stopping agent...", flush=True)
                    agent.running = False
                    exit_requested.set()
                    break
                
                # Short sleep to allow signal handling - check exit frequently
                time.sleep(0.1)  # 100ms - allows signal handler to work
    
    except KeyboardInterrupt:
        print("\nüõë Keyboard interrupt detected!")
        exit_requested.set()
        agent.running = False
    
    finally:
        # Force stop everything - non-blocking
        try:
        agent.stop_monitoring()
        except Exception:
            pass  # Ignore errors during shutdown
        
        # Export data if requested (fast, don't let it block exit)
        if args.output == 'json':
            try:
            data = agent.export_monitoring_data()
            print(json.dumps(data, indent=2))
            except Exception:
                pass  # Don't block exit on export errors

if __name__ == "__main__":
    main()
